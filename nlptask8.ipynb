{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2S/zXRcIfEkYx5tNMHoLZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7YlQG4DsSWOv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"06db2070"},"source":["### 1. Load and preprocess data\n","\n","We'll start by loading a dataset. For this example, we'll create a small, simple dataset. In a real-world scenario, you would load a properly annotated corpus."]},{"cell_type":"markdown","metadata":{"id":"f7ff5148"},"source":["### 2. Estimate probabilities\n","\n","Now, let's calculate the transition and emission probabilities from our dataset. We'll use simple frequency counts for this example. For better performance, smoothing techniques are often used in practice."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0a36b15","executionInfo":{"status":"ok","timestamp":1758173282201,"user_tz":-330,"elapsed":11,"user":{"displayName":"MAADHAM REDDYLAKSHMI,CSE(2022) Vel Tech, Chennai","userId":"02155497753756987257"}},"outputId":"ab9d9edf-f27c-4e14-96aa-36632750c430"},"source":["from collections import defaultdict\n","\n","# Initialize counts\n","transition_counts = defaultdict(lambda: defaultdict(int))\n","emission_counts = defaultdict(lambda: defaultdict(int))\n","tag_counts = defaultdict(int)\n","starting_tag_counts = defaultdict(int)\n","\n","# Populate counts\n","for tag_sequence, sentence in zip(tags, sentences):\n","    starting_tag_counts[tag_sequence[0]] += 1\n","    for i in range(len(tag_sequence)):\n","        tag_counts[tag_sequence[i]] += 1\n","        emission_counts[tag_sequence[i]][sentence[i]] += 1\n","        if i > 0:\n","            transition_counts[tag_sequence[i-1]][tag_sequence[i]] += 1\n","\n","# Calculate probabilities\n","transition_probabilities = defaultdict(lambda: defaultdict(float))\n","emission_probabilities = defaultdict(lambda: defaultdict(float))\n","starting_probabilities = defaultdict(float)\n","\n","for tag, next_tags in transition_counts.items():\n","    total_transitions = sum(next_tags.values())\n","    for next_tag, count in next_tags.items():\n","        transition_probabilities[tag][next_tag] = count / total_transitions\n","\n","for tag, words in emission_counts.items():\n","    total_emissions = sum(words.values())\n","    for word, count in words.items():\n","        emission_probabilities[tag][word] = count / total_emissions\n","\n","total_starting_tags = sum(starting_tag_counts.values())\n","for tag, count in starting_tag_counts.items():\n","    starting_probabilities[tag] = count / total_starting_tags\n","\n","print(\"\\nTransition Probabilities:\")\n","for tag, next_tags in transition_probabilities.items():\n","    print(f\"{tag}: {dict(next_tags)}\")\n","\n","print(\"\\nEmission Probabilities:\")\n","for tag, words in emission_probabilities.items():\n","    print(f\"{tag}: {dict(words)}\")\n","\n","print(\"\\nStarting Probabilities:\")\n","print(dict(starting_probabilities))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Transition Probabilities:\n","DET: {'NOUN': 1.0}\n","NOUN: {'VERB': 1.0}\n","VERB: {'PREP': 0.3333333333333333, 'ADV': 0.3333333333333333, 'ADJ': 0.3333333333333333}\n","PREP: {'DET': 1.0}\n","\n","Emission Probabilities:\n","DET: {'The': 0.5, 'the': 0.25, 'A': 0.25}\n","NOUN: {'cat': 0.25, 'mat': 0.25, 'dog': 0.25, 'bird': 0.25}\n","VERB: {'sat': 0.3333333333333333, 'ran': 0.3333333333333333, 'flew': 0.3333333333333333}\n","PREP: {'on': 1.0}\n","ADV: {'away': 1.0}\n","ADJ: {'high': 1.0}\n","\n","Starting Probabilities:\n","{'DET': 1.0}\n"]}]},{"cell_type":"markdown","metadata":{"id":"c44c9eae"},"source":["### 3. Implement Viterbi algorithm\n","\n","Now, let's implement the Viterbi algorithm to find the most likely tag sequence for a given sentence."]},{"cell_type":"markdown","metadata":{"id":"a6449db3"},"source":["### 4. Evaluate the tagger\n","\n","Now, let's evaluate the performance of our Viterbi POS tagger. We'll use the provided dataset as a simple test set."]}]}