{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvITZygTQabaKl5ukX7Y+i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eP-T_sCV5BB","executionInfo":{"status":"ok","timestamp":1755758282928,"user_tz":-330,"elapsed":76787,"user":{"displayName":"MAADHAM REDDYLAKSHMI,CSE(2022) Vel Tech, Chennai","userId":"02155497753756987257"}},"outputId":"7dac7aca-e0ae-4596-d649-9e9b4cc077c3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Enter a sentence: i am lakshmi\n","Enter the value of N for N-grams: 1\n","Next words: l s m\n"]}],"source":["from nltk.util import ngrams\n","from nltk.lm import Laplace\n","from nltk.tokenize import word_tokenize\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","import nltk\n","nltk.download('punkt_tab')\n","def ngram_smoothing(sentence, n):\n","    tokens = word_tokenize(sentence.lower())\n","    train_data, padded_sents = padded_everygram_pipeline(n, tokens)\n","    model = Laplace(n)\n","    model.fit(train_data, padded_sents)\n","    return model\n","\n","sentence = input(\"Enter a sentence: \")\n","n = int(input(\"Enter the value of N for N-grams: \"))\n","\n","model = ngram_smoothing(sentence, n)\n","context_words = sentence.lower().split()\n","context = tuple(context_words[max(0, len(context_words) - n + 1):])\n","\n","if len(context) < n - 1:\n","    context = (None,) * (n - 1 - len(context)) + context\n","next_words = model.generate(3, text_seed=context)\n","print(\"Next words:\", ' '.join(next_words))"]}]}